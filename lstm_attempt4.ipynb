{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# import plotly.express as px\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reading data files \n",
    "run_name = 'Run3'\n",
    "\n",
    "tsg_screen_data = pd.read_excel('./TSGscreen/' + run_name+'.xlsx')\n",
    "tsg_screen_data.dropna(axis=0)\n",
    "tsg_screen_data.dtypes\n",
    "tsg_screen_data['Time'] = pd.to_datetime(tsg_screen_data['Time'],format='%H:%M:%S')\n",
    "tsg_screen_data.head()\n",
    "feeder_data = pd.read_excel('./Feederdata/' + run_name+'.xlsx')\n",
    "feeder_data = feeder_data.dropna(axis=1)\n",
    "feeder_data['Time'] = pd.to_datetime(feeder_data['Time'],format='%H:%M:%S')\n",
    "feeder_data.head()\n",
    "eyecon_data = pd.read_excel('./Eyecondata/' + run_name+'.xlsx')\n",
    "eyecon_data['Time'] = pd.to_datetime(eyecon_data['Time'],format='%H:%M:%S')\n",
    "eyecon_data.head()\n",
    "feed_eyecon = pd.merge_asof(eyecon_data,feeder_data,on='Time', tolerance=pd.Timedelta('2s'))\n",
    "feed_eyecon = feed_eyecon.dropna(axis=0)\n",
    "len(feed_eyecon)\n",
    "\n",
    "combined_Data = pd.merge_asof(feed_eyecon,tsg_screen_data,on='Time', tolerance=pd.Timedelta('2s'))\n",
    "combined_Data = combined_Data.dropna(axis=0)\n",
    "combined_Data.columns.values\n",
    "# plot_cols = [' D_v50', 'Torque','Zone 2','Zone 3','Zone 4','Zone 5','Zone 6','Zone 7','Zone 8']\n",
    "# plot_cols = ['Zone 2','Zone 3','Zone 4','Zone 5','Zone 6','Zone 7','Zone 8']\n",
    "plot_cols = [' D_v50', 'Torque']\n",
    "time_arr = combined_Data.pop(combined_Data.columns.values[1])\n",
    "plot_features = combined_Data[plot_cols]\n",
    "plot_features.index = time_arr\n",
    "_ = plot_features.plot(subplots=True)\n",
    "combined_Data = combined_Data.drop([' TimeStamp','TimeStamp'],axis=1)\n",
    "combined_Data = combined_Data.drop([' D_v10', ' D_v90', ' D_n10',' D_n50', ' D_n90', ' Median diameter',' Std deviation',' Shape mean', ' Shape RSD', '7 Massflow','7 Setpoint', '7 ScrewSpeed', '7 AveFeedFactor','7 DriveCommand'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler()\n",
    "Y_scaler = MinMaxScaler()\n",
    "\n",
    "X_data = X_scaler.fit_transform(combined_Data[['Mass flow rate','7 NetWeight','Liquid flow rate','Actual RPM','Torque']])\n",
    "Y_data = Y_scaler.fit_transform(combined_Data[['Torque']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ts_multi_data_prep(dataset, target, start, end, window, horizon):\n",
    "    X = []\n",
    "    y = []\n",
    "    start = start + window\n",
    "    if end is None:\n",
    "        end = len(dataset) - horizon\n",
    "    for i in range(start, end):\n",
    "        indices = range(i-window, i)\n",
    "        X.append(dataset[indices])\n",
    "        indicey = range(i+1, i+1+horizon)\n",
    "        y.append(target[indicey])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_window = 60\n",
    "horizon = 60\n",
    "TRAIN_SPLIT = 140\n",
    "x_train, y_train = custom_ts_multi_data_prep(X_data, Y_data, 0, TRAIN_SPLIT, hist_window, horizon)\n",
    "x_vali, y_vali = custom_ts_multi_data_prep(X_data, Y_data, TRAIN_SPLIT, None, hist_window, horizon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('Multiple window of past history\\n')\n",
    "# print(x_train[0])\n",
    "print ('\\n Target horizon\\n')\n",
    "print (y_train[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data and validation data using the TensorFlow data function, which faster and efficient way to feed data for training.\n",
    "batch_size = 128\n",
    "buffer_size = 32\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
    "val_data = val_data.batch(batch_size).repeat() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(6, return_sequences=True), \n",
    "                            input_shape=x_train.shape[-2:]),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(4)),\n",
    "    # tf.keras.layers.Dense(20, activation='tanh'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(units=horizon),\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mae')\n",
    "lstm_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Bidirectional_LSTM_Multivariate.h5'\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "# history = lstm_model.fit(train_data,epochs=150,steps_per_epoch=10,validation_data=val_data,validation_steps=50,verbose=1,callbacks=callbacks)\n",
    "history = lstm_model.fit(train_data,epochs=150,steps_per_epoch=100,validation_data=val_data,validation_steps=100,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'validation loss'])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = X_scaler.fit_transform(combined_Data[['Mass flow rate','7 NetWeight','Liquid flow rate','Actual RPM','Torque']].tail(horizon+1))\n",
    "val_rescaled = data_val.reshape(1, data_val.shape[0], data_val.shape[1])\n",
    "pred = lstm_model.predict(val_rescaled)\n",
    "pred_Inverse = Y_scaler.inverse_transform(pred)\n",
    "pred_Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n') \n",
    "\n",
    "validate=Y_scaler.inverse_transform(val_rescaled[0])\n",
    "timeseries_evaluation_metrics_func(validate[-(horizon+1):-1,-1],pred_Inverse[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot( list(validate[-(horizon+1):-1,-1]))\n",
    "plt.plot( list(pred_Inverse[0]))\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.ylabel(\"Traffic volume\")\n",
    "plt.legend(('Actual','predicted'))\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef7cd0469155a29afd544290d573430e35716703753df15e7b5f11a91b75929"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
